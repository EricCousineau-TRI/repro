{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_grad(p):\n",
    "    if p.grad is not None:\n",
    "        p.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_loss(y, yh):\n",
    "    return torch.abs(y - yh)\n",
    "\n",
    "def mse_loss(y, yh):\n",
    "    return (y - yh)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-citizenship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(p, x):\n",
    "    # Simple (verrrry) linear model.\n",
    "    return p * x\n",
    "\n",
    "def fit(p_gt, loss_fn, lr, num_epochs=3, x=[1.0, 3.0]):\n",
    "    # Expected param + labeled dataset.\n",
    "    p_gt = torch.tensor(p_gt)\n",
    "    x = torch.tensor(x)\n",
    "    y = f(p_gt, x)\n",
    "\n",
    "    # Param to optimize\n",
    "    p = torch.tensor(1.0, requires_grad=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Batch size = 1\n",
    "        for epoch_batch_idx, (xi, yi) in enumerate(zip(x, y)):\n",
    "            # Show err.\n",
    "            p_err = p.detach() - p_gt\n",
    "            print((epoch, epoch_batch_idx), \"p_err:\", p_err)\n",
    "\n",
    "            zero_grad(p)\n",
    "            yhi = f(p, xi)\n",
    "            loss = loss_fn(yi, yhi)\n",
    "            loss.backward()\n",
    "\n",
    "            # SGD update, no momentum.\n",
    "            with torch.no_grad():\n",
    "                v = p.grad  # velocity\n",
    "                p -= lr * v  # step\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-court",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal step size for linear model w/ mse loss\n",
    "fit(p_gt=3.0, loss_fn=mse_loss, lr=0.5, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 loss is param dependent :( (just see grad)\n",
    "\n",
    "# Base case - meh. Takes two well-conditioned minibatches.\n",
    "fit(p_gt=3.0, loss_fn=l1_loss, lr=0.5)\n",
    "# Shift data via expected param. Takes longer to converge (duh).\n",
    "fit(p_gt=5.0, loss_fn=l1_loss, lr=0.5)\n",
    "# Shift data via data points. Now has a stable (but shitty) orbit.\n",
    "fit(p_gt=3.0, loss_fn=l1_loss, lr=0.5, x=[1.0, 20.0], num_epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-cooler",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
