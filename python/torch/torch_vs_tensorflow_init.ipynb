{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175c7dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e313de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba04477",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = 256\n",
    "# out_dim = 256\n",
    "out_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b739cea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "tf_norm_init = tf.keras.initializers.get(\"normal\")  # \"random_normal\"\n",
    "\n",
    "def tf_init(var):\n",
    "    var.assign(tf_norm_init(var.shape))\n",
    "\n",
    "# Compile it ('cause I dunno what else to do it with.)\n",
    "tf_module = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(in_dim,)),\n",
    "    tf.keras.layers.Dense(out_dim),\n",
    "])\n",
    "\n",
    "tf_dense = tf_module.layers[0]\n",
    "tf_init(tf_dense.kernel)\n",
    "tf_init(tf_dense.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a4c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(0)\n",
    "\n",
    "def torch_init(p):\n",
    "    # Match w/ default for normal.\n",
    "    p.data.normal_(mean=tf_norm_init.mean, std=tf_norm_init.stddev)\n",
    "\n",
    "torch_dense = torch.nn.Linear(in_features=in_dim, out_features=out_dim)\n",
    "torch_init(torch_dense.weight)\n",
    "torch_init(torch_dense.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a61942",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"/tmp/log\"\n",
    "max_bins = 256\n",
    "!rm -rf {log_dir}\n",
    "writer = SummaryWriter(log_dir)\n",
    "for step in [0, 1]:\n",
    "    writer.add_histogram(\"tf/weight\", tf_dense.kernel.numpy(), step, max_bins=max_bins)\n",
    "    writer.add_histogram(\"tf/bias\", tf_dense.bias.numpy(), step, max_bins=max_bins)\n",
    "    writer.add_histogram(\"torch/weight\", torch_dense.weight.detach().numpy(), step, max_bins=max_bins)\n",
    "    writer.add_histogram(\"torch/bias\", torch_dense.bias.detach().numpy(), step, max_bins=max_bins)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b8b381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kinda weird to see the scalar values listed as a block... but meh.\n",
    "%tensorboard --logdir {log_dir}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
